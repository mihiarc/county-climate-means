# Climate Data Processing Project

## üåç Project Overview

This project implements a high-performance climate data processing pipeline for computing rolling 30-year climate normals from NorESM2-LM climate model data. The system processes multiple climate variables across different scenarios and geographic regions, with optimized multiprocessing capabilities and comprehensive monitoring.

## üìä Project Architecture

```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    subgraph "Input Data"
        A[NorESM2-LM NetCDF Files]
        A1[pr - Precipitation]
        A2[tas - Temperature]
        A3[tasmax - Max Temperature]
        A4[tasmin - Min Temperature]
        A --> A1
        A --> A2
        A --> A3
        A --> A4
    end

    subgraph "Processing Engine"
        B[Main Processing Pipelines]
        B1[Sequential Pipeline<br/>process_all_climate_normals.py]
        B2[Multiprocessing Pipeline<br/>process_climate_normals_multiprocessing.py]
        B3[Core Engine<br/>climate_means.py]
        B4[MP Engine<br/>climate_multiprocessing.py]
        
        B --> B1
        B --> B2
        B1 --> B3
        B2 --> B4
    end

    subgraph "Utility Modules"
        C[Support Systems]
        C1[I/O Operations<br/>io_util.py]
        C2[Regional Processing<br/>regions.py]
        C3[Time Handling<br/>time_util.py]
        C4[Optimization<br/>optimize.py]
        
        C --> C1
        C --> C2
        C --> C3
        C --> C4
    end

    subgraph "Monitoring & Status"
        D[Tracking Systems]
        D1[Progress Monitor<br/>monitor_progress.py]
        D2[Status Checker<br/>status.py]
        
        D --> D1
        D --> D2
    end

    subgraph "Output Products"
        E[Climate Normals]
        E1[Historical Normals<br/>1980-2014]
        E2[Hybrid Normals<br/>2015-2044]
        E3[Future Normals<br/>2045-2100]
        
        E --> E1
        E --> E2
        E --> E3
    end

    A --> B
    B --> C
    B --> D
    B --> E
    
    style A fill:#1e3a8a,stroke:#60a5fa,stroke-width:2px,color:#f1f5f9
    style B fill:#581c87,stroke:#a855f7,stroke-width:2px,color:#f1f5f9
    style C fill:#14532d,stroke:#4ade80,stroke-width:2px,color:#f1f5f9
    style D fill:#9a3412,stroke:#fb923c,stroke-width:2px,color:#f1f5f9
    style E fill:#881337,stroke:#f472b6,stroke-width:2px,color:#f1f5f9
```

## üîÑ Data Processing Flow

```mermaid
%%{init: {'theme':'dark'}}%%
flowchart TD
    Start([Start Processing]) --> Input[Load NorESM2-LM Data]
    
    Input --> FileHandler[NorESM2FileHandler<br/>- Validate data availability<br/>- Extract file metadata<br/>- Organize by scenario]
    
    FileHandler --> RegionSelect{Select Region}
    RegionSelect --> CONUS[CONUS]
    RegionSelect --> Alaska[Alaska]
    RegionSelect --> Hawaii[Hawaii]
    RegionSelect --> PRVI[Puerto Rico/VI]
    RegionSelect --> Guam[Guam/CNMI]
    
    CONUS --> VarSelect{Select Variable}
    Alaska --> VarSelect
    Hawaii --> VarSelect
    PRVI --> VarSelect
    Guam --> VarSelect
    
    VarSelect --> PR[Precipitation]
    VarSelect --> TAS[Temperature]
    VarSelect --> TASMAX[Max Temperature]
    VarSelect --> TASMIN[Min Temperature]
    
    PR --> PeriodType{Period Type}
    TAS --> PeriodType
    TASMAX --> PeriodType
    TASMIN --> PeriodType
    
    PeriodType --> Historical[Historical<br/>1980-2014<br/>Historical data only]
    PeriodType --> Hybrid[Hybrid<br/>2015-2044<br/>Historical + SSP245]
    PeriodType --> Future[Future<br/>2045-2100<br/>SSP245 only]
    
    Historical --> ProcessFiles[Process Individual Files]
    Hybrid --> ProcessFiles
    Future --> ProcessFiles
    
    ProcessFiles --> DailyClim[Calculate Daily Climatology<br/>- Extract region<br/>- Group by day-of-year<br/>- Compute daily means]
    
    DailyClim --> ClimateNormal[Compute 30-Year Normal<br/>- Combine 30 years of data<br/>- Average across years<br/>- Add metadata]
    
    ClimateNormal --> SaveOutput[Save Results<br/>- Individual files<br/>- Combined datasets<br/>- NetCDF format]
    
    SaveOutput --> Monitor[Update Progress<br/>- JSON status file<br/>- Progress logs<br/>- Performance metrics]
    
    Monitor --> Complete([Processing Complete])
    
    style Start fill:#166534,stroke:#4ade80,stroke-width:3px,color:#f1f5f9
    style Complete fill:#166534,stroke:#4ade80,stroke-width:3px,color:#f1f5f9
    style ProcessFiles fill:#1e40af,stroke:#60a5fa,stroke-width:2px,color:#f1f5f9
    style DailyClim fill:#c2410c,stroke:#fb923c,stroke-width:2px,color:#f1f5f9
    style ClimateNormal fill:#7c2d12,stroke:#a855f7,stroke-width:2px,color:#f1f5f9
    style SaveOutput fill:#991b1b,stroke:#f87171,stroke-width:2px,color:#f1f5f9
```

## üöÄ Performance Architecture

```mermaid
%%{init: {'theme':'dark'}}%%
graph LR
    subgraph "Sequential Processing"
        A1[Single Process]
        A2[Linear File Processing]
        A3[Memory Efficient]
        A4[~4-5 hours total]
    end
    
    subgraph "Multiprocessing System"
        B1[Variable-Level Parallelism<br/>4 Variables √ó 6 Cores = 24 cores]
        B2[Batch Processing<br/>Target years in batches of 2]
        B3[Process Pool Executor]
        B4[~45 minutes total<br/>4.3x speedup]
    end
    
    subgraph "Optimization Features"
        C1[Memory Management<br/>4GB per worker limit]
        C2[Progress Tracking<br/>Real-time status updates]
        C3[Crash Resistance<br/>Skip corrupted files]
        C4[Resume Capability<br/>Skip completed files]
    end
    
    A1 --> A2 --> A3 --> A4
    B1 --> B2 --> B3 --> B4
    
    B1 -.-> C1
    B2 -.-> C2
    B3 -.-> C3
    B4 -.-> C4
    
    style A4 fill:#7f1d1d,stroke:#f87171,stroke-width:2px,color:#f1f5f9
    style B4 fill:#14532d,stroke:#4ade80,stroke-width:2px,color:#f1f5f9
```

## üìÇ Output Structure

```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    Root[output/rolling_30year_climate_normals/]
    
    Root --> PR[pr/]
    Root --> TAS[tas/]
    Root --> TASMAX[tasmax/]
    Root --> TASMIN[tasmin/]
    
    PR --> PR_HIST[historical/]
    PR --> PR_HYB[hybrid/]
    PR --> PR_SSP[ssp245/]
    
    TAS --> TAS_HIST[historical/]
    TAS --> TAS_HYB[hybrid/]
    TAS --> TAS_SSP[ssp245/]
    
    TASMAX --> TASMAX_HIST[historical/]
    TASMAX --> TASMAX_HYB[hybrid/]
    TASMAX --> TASMAX_SSP[ssp245/]
    
    TASMIN --> TASMIN_HIST[historical/]
    TASMIN --> TASMIN_HYB[hybrid/]
    TASMIN --> TASMIN_SSP[ssp245/]
    
    PR_HIST --> PR_HIST_FILES[pr_CONUS_historical_YYYY_30yr_normal.nc<br/>pr_CONUS_historical_1980-2014_all_normals.nc]
    PR_HYB --> PR_HYB_FILES[pr_CONUS_hybrid_YYYY_30yr_normal.nc<br/>pr_CONUS_hybrid_2015-2044_all_normals.nc]
    PR_SSP --> PR_SSP_FILES[pr_CONUS_ssp245_YYYY_30yr_normal.nc<br/>pr_CONUS_ssp245_2045-2100_all_normals.nc]
    
    style Root fill:#1e3a8a,stroke:#60a5fa,stroke-width:2px,color:#f1f5f9
    style PR_HIST_FILES fill:#166534,stroke:#4ade80,stroke-width:2px,color:#f1f5f9
    style PR_HYB_FILES fill:#a16207,stroke:#fbbf24,stroke-width:2px,color:#f1f5f9
    style PR_SSP_FILES fill:#881337,stroke:#f472b6,stroke-width:2px,color:#f1f5f9
```

## üõ†Ô∏è Key Components

### Core Processing Modules

| Module | Purpose | Key Features |
|--------|---------|--------------|
| `climate_means.py` | Core climate calculations | Sequential processing, climate normal computation, crash resistance |
| `climate_multiprocessing.py` | High-performance processing | 6-worker optimization, 4.3x speedup, memory management |
| `process_all_climate_normals.py` | Sequential pipeline | Comprehensive processing, all variables/periods |
| `process_climate_normals_multiprocessing.py` | MP pipeline | 24-core utilization, progress tracking, resume capability |

### Utility Modules

| Module | Purpose | Key Features |
|--------|---------|--------------|
| `io_util.py` | File I/O operations | NetCDF handling, NorESM2 file structure, safe dataset opening |
| `regions.py` | Geographic processing | Regional bounds, coordinate conversion, spatial extraction |
| `time_util.py` | Time handling | Period generation, time coordinates, climatology calculations |
| `optimize.py` | Performance optimization | Chunking strategies, memory benchmarking, multiprocessing tests |

### Monitoring & Status

| Module | Purpose | Key Features |
|--------|---------|--------------|
| `monitor_progress.py` | Real-time monitoring | Live progress display, performance metrics, ETA calculation |
| `status.py` | Quick status check | File count analysis, completion tracking, recent activity |

## üìà Performance Metrics

### Multiprocessing Optimization Results

| Configuration | Time | Speedup | Efficiency | Throughput |
|---------------|------|---------|------------|------------|
| Sequential (1 worker) | 15.4s | 1.0x | 100% | 0.32 files/s |
| **Optimal (6 workers)** | **3.6s** | **4.3x** | **72%** | **1.41 files/s** |
| Excessive (8+ workers) | 3.6s | 4.3x | <54% | ~1.40 files/s |

### Processing Targets

| Variable | Historical | Hybrid | SSP245 | Total |
|----------|------------|--------|--------|-------|
| pr | 35 files | 30 files | 32 files | 97 files |
| tas | 35 files | 30 files | 85 files | 150 files |
| tasmax | 35 files | 30 files | 85 files | 150 files |
| tasmin | 35 files | 30 files | 85 files | 150 files |
| **Total** | **140 files** | **120 files** | **287 files** | **547 files** |

## üéØ Usage Examples

### Sequential Processing
```python
from src.process_all_climate_normals import main
main()  # Process all variables sequentially
```

### Multiprocessing Pipeline
```python
from src.process_climate_normals_multiprocessing import main
main()  # High-performance parallel processing
```

### Progress Monitoring
```bash
python src/monitor_progress.py  # Real-time monitoring
python src/status.py           # Quick status check
```

### Performance Testing
```python
from src.optimize import SafeOptimizer
optimizer = SafeOptimizer("/path/to/data")
optimizer.run_optimization_analysis()
```

## üîß Configuration

### System Requirements
- **CPU**: 24+ cores recommended for multiprocessing
- **RAM**: 80GB+ for optimal performance
- **Storage**: High-performance SSD for NetCDF I/O
- **Python**: 3.8+ with scientific computing stack

### Key Parameters
- `MAX_CORES`: 24 (total system utilization)
- `CORES_PER_VARIABLE`: 6 (optimal from testing)
- `BATCH_SIZE_YEARS`: 2 (memory management)
- `MAX_MEMORY_PER_PROCESS_GB`: 4 (conservative limit)
- `MIN_YEARS_FOR_NORMAL`: 25 (minimum for climate normal)

## üìä Data Sources

- **Model**: NorESM2-LM (Norwegian Earth System Model)
- **Variables**: 
  - `pr`: Precipitation (kg m‚Åª¬≤ s‚Åª¬π)
  - `tas`: Near-surface air temperature (K)
  - `tasmax`: Daily maximum temperature (K)
  - `tasmin`: Daily minimum temperature (K)
- **Scenarios**: 
  - `historical`: 1850-2014
  - `ssp245`: 2015-2100 (Shared Socioeconomic Pathway 2-4.5)
- **Regions**: CONUS, Alaska, Hawaii, Puerto Rico & VI, Guam & CNMI

## üéâ Project Achievements

- ‚úÖ **High Performance**: 4.3x speedup with multiprocessing optimization
- ‚úÖ **Comprehensive Coverage**: All 4 variables √ó 3 periods √ó 5 regions
- ‚úÖ **Robust Processing**: Crash resistance, memory management, resume capability
- ‚úÖ **Real-time Monitoring**: Progress tracking, performance metrics, status updates
- ‚úÖ **Scientific Quality**: 30-year climate normals following WMO standards
- ‚úÖ **Modular Design**: Clean separation of concerns, reusable components
- ‚úÖ **Production Ready**: Optimized for large-scale climate data processing 